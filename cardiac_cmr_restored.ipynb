{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "import scipy.io as sio\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "import random\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "# from tqdm import tqdm_notebook, tnrange\n",
    "# from itertools import chain\n",
    "# from skimage.io import imread, imshow, concatenate_images\n",
    "# from skimage.transform import resize\n",
    "# from skimage.morphology import label\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "print(Image.__file__)\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):\n",
    "    # first layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size),\n",
    "               padding=\"same\")(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    # second layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size),\n",
    "               padding=\"same\")(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(input_img, n_filters=16, dropout=0.5, batchnorm=True):\n",
    "    # contracting path\n",
    "    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=False)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "    p1 = Dropout(dropout*0.5)(p1)\n",
    "\n",
    "    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=True)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "\n",
    "    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=True)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "\n",
    "    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=True)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=True)\n",
    "    \n",
    "    # expansive path\n",
    "    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=True)\n",
    "\n",
    "    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=True)\n",
    "\n",
    "    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=True)\n",
    "\n",
    "    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=False)\n",
    "    \n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator(batch_size,mask_type = \"lv_endo\",mode=\"train\",shuffle_var = False):\n",
    "    #lv_endo 001\n",
    "    #lv_epi 002\n",
    "    #rv_endo 003\n",
    "    #rv_epi 004\n",
    "#     shuffle_var = False \n",
    "    mask_directory = {\"lv_endo\":1,\"lv_epi\":2,\"rv_endo\":3,\"rv_epi\":4}\n",
    "    data_gen_args = dict(rescale = 1./255,\n",
    "                         rotation_range=10,\n",
    "                         width_shift_range=0.1,\n",
    "                         height_shift_range=0.1,\n",
    "                         zoom_range=0.2)\n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    seed = 1\n",
    "#     if mode == \"train\":\n",
    "#         shuffle_var = True \n",
    "        \n",
    "    image_generator = image_datagen.flow_from_directory('mri/'+mode+'/images/',class_mode ='binary',target_size =(192,192),\n",
    "        color_mode='grayscale',batch_size = batch_size,shuffle = shuffle_var,seed=seed)\n",
    "#     print('/home/ubuntu/mri/train/train_00'+str(mask_directory[mask_type])+'/masks/masks/')\n",
    "    mask_generator = mask_datagen.flow_from_directory('mri/'+mode+'/'+mode+'_00'+str(mask_directory[mask_type])+'/masks/',\n",
    "        class_mode ='binary',target_size =(192,192),color_mode='grayscale',batch_size = batch_size,shuffle = shuffle_var,\n",
    "        seed=seed)\n",
    "#     train_generator = zip(image_generator, mask_generator)\n",
    "    while True:\n",
    "        yield (image_generator.next()[0], mask_generator.next()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen = np.ones((1,192,192,1))\n",
    "mask_gen = np.ones((1,192,192,1))\n",
    "# image_gen = image.reshape(image,(1,image.shape[0],image.shape[1],1))\n",
    "# mask_gen = image.reshape(mask,(1,image.shape[0],image.shape[1],1))\n",
    "# image_batch, mask_batch = next(create_generator(image_gen, mask_gen, 8,\"lv_endo\"))\n",
    "image_batch, mask_batch = next(create_generator(16,mask_type =\"lv_endo\",mode=\"train\",shuffle_var=True))\n",
    "print(mask_batch.shape)\n",
    "print(image_batch.shape)\n",
    "fix, ax = plt.subplots(8,2, figsize=(8,20))\n",
    "\n",
    "for i in range(8):\n",
    "    ax[i,0].imshow(image_batch[i,:,:,0],cmap = 'gray')\n",
    "    ax[i,1].imshow(mask_batch[i,:,:,0],cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + K.epsilon()) / (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input((192, 192, 1), name='img')\n",
    "model = get_unet(input_img, n_filters=16, dropout=0.5, batchnorm=True)\n",
    "\n",
    "model.compile(optimizer=Adam(lr=1e-3), loss='binary_crossentropy', metrics=[dice_coef])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rv_epi = model \n",
    "model_lv_epi = model\n",
    "model_rv_endo = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "hist_endo = model.fit_generator(create_generator(batch_size,\"lv_endo\",mode=\"train\",shuffle_var=True),\n",
    "                           steps_per_epoch = 6930//batch_size,\n",
    "                           epochs=10, verbose=1,validation_data = create_generator(batch_size,mask_type =\"lv_endo\",mode=\"val\"),\n",
    "                           validation_steps =1470//batch_size)\n",
    "model.save_weights('lv_endo_newdata10_epochs.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lv_epi = get_unet(input_img, n_filters=16, dropout=0.5, batchnorm=True)\n",
    "\n",
    "model_lv_epi.compile(optimizer=Adam(lr=1e-3), loss='binary_crossentropy', metrics=[dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_lv_epi = model_lv_epi.fit_generator(create_generator(16,\"lv_epi\",mode=\"train\",shuffle_var=True),\n",
    "                           steps_per_epoch = 6930//batch_size,\n",
    "                           epochs=10, verbose=1,validation_data = create_generator(16,mask_type =\"lv_epi\",mode=\"val\"),\n",
    "                           validation_steps = 1470//batch_size)\n",
    "model_lv_epi.save_weights('lv_epi_newdata10_epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rv_endo = get_unet(input_img, n_filters=16, dropout=0.5, batchnorm=True)\n",
    "\n",
    "model_rv_endo.compile(optimizer=Adam(lr=1e-3), loss='binary_crossentropy', metrics=[dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_rv_endo = model_rv_endo.fit_generator(create_generator(16,\"rv_endo\",mode=\"train\",shuffle_var=True),\n",
    "                           steps_per_epoch = 6930//batch_size,\n",
    "                           epochs=10, verbose=1,validation_data = create_generator(16,mask_type =\"rv_endo\",mode=\"val\"),\n",
    "                           validation_steps = 1470//batch_size)\n",
    "model_rv_endo.save_weights('rv_endo_newdata10_epochs.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test predictions and Saving the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('lv_endo_newdata10_epochs.h5')\n",
    "# model_lv_epi.load_weights('lv_endo_10_epochs.h5')\n",
    "# model_rv_endo.load_weights('rv_endo_10_epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gen(model,mask_type):\n",
    "    mask_type_dict = {\"lv_endo\":[\"001\",\"a\"],\"lv_epi\":[\"002\",\"b\"],\"rv_endo\":[\"003\",\"c\"]}\n",
    "    test_datagen_images = ImageDataGenerator(rescale = 1./255)\n",
    "    seed = 1\n",
    "    test_image_generator = test_datagen_images.flow_from_directory('mri/test/images',class_mode ='binary',target_size =(192,192),\n",
    "                        shuffle =False,color_mode='grayscale',batch_size = 8,seed=seed)\n",
    "\n",
    "    STEP_SIZE_TEST=test_image_generator.n//8\n",
    "    lv_endo_predict = model.predict_generator(test_image_generator, steps = test_image_generator.n//8,verbose = 1)\n",
    "    return lv_endo_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lv_endo_predict = predict_gen(model,mask_type=\"lv_endo\")\n",
    "# lv_epi_predict,ground_mask_lv_epi=predict_gen(model_lv_epi,mask_type=\"lv_epi\")\n",
    "# rv_endo_predict,ground_mask_rv_endo=predict_gen(model_rv_endo,mask_type=\"rv_endo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(lv_endo_predict[20][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold predictions\n",
    "def save_to_png(image_array,mask_type):\n",
    "    dir_to_save='/home/ubuntu/mri/test/'\n",
    "    mask_type_dict = {\"lv_endo\":[\"001\",\"a\"],\"lv_epi\":[\"002\",\"b\"],\"rv_endo\":[\"003\",\"c\"]}\n",
    "    dir_to_save = dir_to_save +'seg_'+mask_type_dict[mask_type][0]+'/masks/masks/'\n",
    "    ind = 0 \n",
    "    df = pd.read_csv('/home/ubuntu/patient_data_attributes_all.csv',index_col = False)\n",
    "    df_id_select = df.loc[df.Mode ==\"test\"]\n",
    "    for study in range(1,int(df_id_select.iloc[-1,:].Image_id[1:5])+1):\n",
    "        df_select = df.loc[(df.Image_id.str.startswith(\"i\"+str(study).zfill(4)))&(df.Mode==\"test\"), :]\n",
    "        for idx in range(len(df_select)):\n",
    "            df_idx = df_select.iloc[idx,:]\n",
    "            im = np.where(image_array[ind][:,:,0]>0.35,1,0)\n",
    "#             im = image_array[ind]\n",
    "            im = 255*im.reshape(192,192).astype(np.uint8)\n",
    "            im = Image.fromarray(im)\n",
    "            im = im.convert(\"L\")\n",
    "            file_dir = os.path.join(dir_to_save,mask_type_dict[mask_type][1]+df_idx[0][1:]+\".png\")\n",
    "            plt.imsave(file_dir, im,cmap=plt.get_cmap('gray'))\n",
    "#             cv2.imwrite(file_dir, im)\n",
    "            ind+=1\n",
    "            print(idx,len(df_select))\n",
    "    \n",
    "\n",
    "save_to_png(lv_endo_predict,mask_type=\"lv_endo\")\n",
    "# lv_endo_datagen=test_datagen_images.flow(lv_endo_predict_thresh,batch_size =batch_size,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(hist_endo):\n",
    "    fig,ax = plt.subplots(1,2,figsize=(10, 5),squeeze = False)\n",
    "\n",
    "    ax[0][0].plot(hist_endo.history[\"loss\"], label=\"loss\")\n",
    "    ax[0][0].plot(hist_endo.history[\"val_loss\"], label=\"val_loss\")\n",
    "    ax[0][0].plot( np.argmin(hist_endo.history[\"val_loss\"]), np.min(hist_endo.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "    ax[0][0].legend();\n",
    "    ax[0][0].set_xlabel(\"Epochs\")\n",
    "    ax[0][0].set_ylabel(\"Loss\")\n",
    "    ax[0][1].plot(hist_endo.history[\"dice_coef\"],label =\"dice_coef\")\n",
    "    ax[0][1].plot(hist_endo.history[\"val_dice_coef\"],label =\"val_dice_coef\")\n",
    "    ax[0][1].legend();\n",
    "    # ax.set_legend();\n",
    "    ax[0][1].set_xlabel(\"Epochs\")\n",
    "    ax[0][1].set_ylabel(\"Dice coefficient\")\n",
    "    plt.show()\n",
    "plot_history(hist_rv_endo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stroke Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def volume_calculation(study,mask_type,mask_mode =\"ground\"):\n",
    "    mask_dir='/home/ubuntu/mri/test/'\n",
    "    ratio_x = 1\n",
    "    ratio_y = 1\n",
    "    mask_type_dict = {\"lv_endo\":[\"001\",\"a\"],\"lv_epi\":[\"002\",\"b\"],\"rv_endo\":[\"003\",\"c\"]}\n",
    "    if mask_mode ==\"ground\":\n",
    "        mask_dir = mask_dir +'test_'+mask_type_dict[mask_type][0]+'/masks/masks/'\n",
    "    elif mask_mode==\"seg\":\n",
    "        mask_dir = mask_dir +'seg_'+mask_type_dict[mask_type][0]+'/masks/masks/'\n",
    "    else:\n",
    "        mask_dir  = None\n",
    "        \n",
    "    df = pd.read_csv('/home/ubuntu/patient_data_attributes_all.csv',index_col = False)\n",
    "    total_volume=[]\n",
    "    index = 0 \n",
    "    df_select = df.loc[(df.Image_id.str.startswith(\"i\"+str(study).zfill(4)))&(df.Mode==\"test\"), :]           \n",
    "    for phase in range(1,int(df_select.iloc[-1,0][5:8])+1 ):\n",
    "        voxel_volume = 0\n",
    "        for slices in range(1,int(df_select.iloc[-1,0][8:])+1):\n",
    "            filename = str(study).zfill(4)+str(phase).zfill(3)+str(slices).zfill(3)\n",
    "            mask_val = np.array(Image.open(mask_dir +mask_type_dict[mask_type][1]+filename+'.png' ))\n",
    "            mask_val = mask_val[:,:,0]\n",
    "            mask_val = mask_val*1./255\n",
    "            mask_val = mask_val.reshape(192,192)\n",
    "            if mask_mode == \"ground\":\n",
    "#                 mask_val = np.where(mask_val>0.5,1,0)\n",
    "#                 mask_val = np.where(mask_val>0.2,1,0)\n",
    "                area = np.sum(mask_val!=0)\n",
    "            elif mask_mode ==\"seg\":\n",
    "                area = np.sum(mask_val==1)\n",
    "            df_idx = df_select.loc[df_select.Image_id==\"i\"+filename]\n",
    "            if (df_idx.Shape_x != 192).bool() or (df_idx.Shape_y != 192).bool():\n",
    "                ratio_x = 192/df_idx.Shape_x\n",
    "                ratio_y = 192/df_idx.Shape_y\n",
    "            V_i = (df_idx.space_between_slice + df_idx.slice_thickness)*area*( df_idx.pixel_size_x *ratio_x*df_idx.pixel_size_y*ratio_y)\n",
    "            voxel_volume+= V_i.values.tolist()[0]\n",
    "        total_volume.append(voxel_volume)\n",
    "    return total_volume \n",
    "\n",
    "def stroke_vol_plot(prediction , truth,mask_type=\"lv_endo\",study = 1):\n",
    "    fig,ax = plt.subplots(1,2,figsize=(12, 6),squeeze = False)\n",
    "    ax[0][0].plot(truth, label=mask_type+\"ground_vol\")\n",
    "    ax[0][0].set_xlabel(\"Phase\")\n",
    "    ax[0][0].set_ylabel(\"Volume\")\n",
    "    ax[0][0].set_title(mask_type + f\" ground Stroke volume:Study {study}\")\n",
    "    ax[0][1].plot(prediction, label=mask_type+\"predicted_vol\")\n",
    "    ax[0][1].set_xlabel(\"Phase\")\n",
    "    ax[0][1].set_ylabel(\"Volume\")\n",
    "    ax[0][1].set_title(mask_type+ f\" predicted Stroke volume:Study {study}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejection Fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ejection_fraction(study , mask_type) :\n",
    "    \n",
    "    lv_gnd_vol = volume_calculation(study , mask_type ,mask_mode=\"ground\")\n",
    "    ESV_gnd = min(lv_gnd_vol)\n",
    "    EDV_gnd = max(lv_gnd_vol)\n",
    "    print(f\"Ground ESV for study_{study}: {ESV_gnd}\" )\n",
    "    print(f\"Ground EDV for study_{study}: {EDV_gnd}\" )\n",
    "    print(f\"Ground Ejection Fraction  for study_{study}: { (EDV_gnd - ESV_gnd)/EDV_gnd}\" )\n",
    "    \n",
    "    lv_pred_vol = volume_calculation(study , mask_type ,mask_mode=\"seg\")\n",
    "    ESV_pred = min(lv_pred_vol)\n",
    "    EDV_pred = max(lv_pred_vol)\n",
    "\n",
    "    print(f\"Predicted ESV for study_{study}: {ESV_pred}\")\n",
    "    print(f\"Predicted EDV for study_{study}: {EDV_pred}\")\n",
    "    print(f\"Predicted Ejection Fraction  for study_{study}: {(EDV_pred-ESV_pred)/EDV_pred}\" )\n",
    "    stroke_vol_plot(lv_pred_vol , lv_gnd_vol ,mask_type=\"lv_endo\",study=study)\n",
    "\n",
    "    ef_offset = (EDV_pred-ESV_pred)/EDV_pred - (EDV_gnd - ESV_gnd)/EDV_gnd\n",
    "    edv_offset = EDV_gnd - EDV_pred\n",
    "    esv_offset = ESV_gnd - ESV_pred\n",
    "    \n",
    "    return ef_offset , edv_offset , esv_offset\n",
    "    \n",
    "# ejection_fraction(study = 2,mask_type=\"lv_endo\")\n",
    "# ejection_fraction(study = 3,mask_type=\"lv_endo\")\n",
    "offset = []\n",
    "for i in range(1,18):\n",
    "    ef_off , edv_off , esv_off = ejection_fraction(study = i,mask_type=\"lv_endo\")\n",
    "    offset.append((ef_off , edv_off , esv_off))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0 \n",
    "fig , ax = plt.subplots(1,2,squeeze = False ,figsize = (10,10))\n",
    "original_image =  np.array(Image.open('mri/test/images/images/i0015020010.png'))\n",
    "mask_val_gnd =  np.array(Image.open('mri/test/test_001/masks/masks/a0015020010.png'))\n",
    "mask_val_gnd = (mask_val_gnd[:,:,0]*1./255).reshape(192,192)\n",
    "mask_val_pred =  np.array(Image.open('mri/test/seg_001/masks/masks/a0015020010.png'))\n",
    "mask_val_pred = (mask_val_pred[:,:,0]*1./255).reshape(192,192)\n",
    "\n",
    "ax[index][0].imshow(original_image[:,:,0]*1./255, 'gray', interpolation='none')\n",
    "ax[index][0].imshow(mask_val_gnd, 'jet', interpolation='none', alpha=0.3)\n",
    "ax[index][0].grid(False)\n",
    "\n",
    "ax[index][1].imshow(original_image, 'gray', interpolation='none')\n",
    "ax[index][1].imshow(mask_val_pred, 'jet', interpolation='none', alpha=0.3)\n",
    "ax[index][1].grid(False)\n",
    "ax[0][0].set_title(\"Ground\")\n",
    "ax[0][1].set_title(\"Prediction\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
